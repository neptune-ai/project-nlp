{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Text classification using Keras with Neptune tracking\n",
                "Notebook inspired from https://keras.io/examples/nlp/text_classification_from_scratch/"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import tensorflow as tf\n",
                "import utils"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "(Neptune) Import Neptune and initialize a project"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "os.environ[\"NEPTUNE_PROJECT\"] = \"showcase/project-text-classification\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "https://app.neptune.ai/showcase/project-text-classification/\n",
                        "Remember to stop your project once you’ve finished logging your metadata (https://docs.neptune.ai/api/project#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
                    ]
                }
            ],
            "source": [
                "import neptune.new as neptune\n",
                "\n",
                "project = neptune.init_project()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data preparation\n",
                "We are using the IMDB sentiment analysis data available at https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz. For the purposes of this demo, we've uploaded this data to S3 at https://neptune-examples.s3.us-east-2.amazonaws.com/data/text-classification/aclImdb_v1.tar.gz and will be downloading it from there."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### (Neptune) Track datasets using Neptune\n",
                "Since this dataset will be used among all the runs in the project, we track it at the project level"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "project[\"keras/data/files\"].track_files(\n",
                "    \"s3://neptune-examples/data/text-classification/aclImdb_v1.tar.gz\"\n",
                ")\n",
                "project.sync()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### (Neptune) Download files from S3 using Neptune"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Downloading data...\n"
                    ]
                }
            ],
            "source": [
                "print(\"Downloading data...\")\n",
                "project[\"keras/data/files\"].download(\"..\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Prepare data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Extracting data...\n",
                        "../aclImdb renamed to ../data\n"
                    ]
                }
            ],
            "source": [
                "utils.extract_files(source=\"../aclImdb_v1.tar.gz\", destination=\"..\")\n",
                "utils.prep_data(imdb_folder=\"../aclImdb\", dest_path=\"../data\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "(Neptune) Upload dataset sample to Neptune project"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "import random\n",
                "\n",
                "base_namespace = \"keras/data/sample/\"\n",
                "\n",
                "project[base_namespace][\"train/pos\"].upload(\n",
                "    f\"../data/train/pos/{random.choice(os.listdir('../data/train/pos'))}\"\n",
                ")\n",
                "project[base_namespace][\"train/neg\"].upload(\n",
                "    f\"../data/train/neg/{random.choice(os.listdir('../data/train/neg'))}\"\n",
                ")\n",
                "project[base_namespace][\"test/pos\"].upload(\n",
                "    f\"../data/test/pos/{random.choice(os.listdir('../data/test/pos'))}\"\n",
                ")\n",
                "project[base_namespace][\"test/neg\"].upload(\n",
                "    f\"../data/test/neg/{random.choice(os.listdir('../data/test/neg'))}\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Generate training, validation, and test datasets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_params = {\n",
                "    \"batch_size\": 32,\n",
                "    \"validation_split\": 0.2,\n",
                "    \"max_features\": 20000,\n",
                "    \"embedding_dim\": 128,\n",
                "    \"sequence_length\": 500,\n",
                "    \"seed\": 42,\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "(Neptune) Log data metadata to Neptune"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "https://app.neptune.ai/showcase/project-text-classification/e/TXTCLF-358\n",
                        "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
                    ]
                }
            ],
            "source": [
                "run = neptune.init_run(name=\"Keras text classification\", tags=[\"keras\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "run[\"data/params\"] = data_params"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.layers import TextVectorization\n",
                "import string\n",
                "import re"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 25000 files belonging to 2 classes.\n",
                        "Using 20000 files for training.\n",
                        "Using 5000 files for validation.\n",
                        "Found 25000 files belonging to 2 classes.\n",
                        "Number of batches in raw_train_ds: 625\n",
                        "Number of batches in raw_val_ds: 157\n",
                        "Number of batches in raw_test_ds: 782\n"
                    ]
                }
            ],
            "source": [
                "raw_train_ds, raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
                "    \"../data/train\",\n",
                "    batch_size=data_params[\"batch_size\"],\n",
                "    validation_split=data_params[\"validation_split\"],\n",
                "    subset=\"both\",\n",
                "    seed=data_params[\"seed\"],\n",
                ")\n",
                "\n",
                "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
                "    \"../data/test\", batch_size=data_params[\"batch_size\"]\n",
                ")\n",
                "\n",
                "print(f\"Number of batches in raw_train_ds: {raw_train_ds.cardinality()}\")\n",
                "print(f\"Number of batches in raw_val_ds: {raw_val_ds.cardinality()}\")\n",
                "print(f\"Number of batches in raw_test_ds: {raw_test_ds.cardinality()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Clean data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:From C:\\Users\\siddh\\miniconda3\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
                        "Instructions for updating:\n",
                        "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
                    ]
                }
            ],
            "source": [
                "def custom_standardization(input_data):\n",
                "    lowercase = tf.strings.lower(input_data)\n",
                "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
                "    return tf.strings.regex_replace(stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\")\n",
                "\n",
                "\n",
                "vectorize_layer = TextVectorization(\n",
                "    standardize=custom_standardization,\n",
                "    max_tokens=data_params[\"max_features\"],\n",
                "    output_mode=\"int\",\n",
                "    output_sequence_length=data_params[\"sequence_length\"],\n",
                ")\n",
                "\n",
                "text_ds = raw_train_ds.map(lambda x, y: x)\n",
                "vectorize_layer.adapt(text_ds)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Vectorize data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "def vectorize_text(text, label):\n",
                "    text = tf.expand_dims(text, -1)\n",
                "    return vectorize_layer(text), label\n",
                "\n",
                "\n",
                "# Vectorize the data.\n",
                "train_ds = raw_train_ds.map(vectorize_text)\n",
                "val_ds = raw_val_ds.map(vectorize_text)\n",
                "test_ds = raw_test_ds.map(vectorize_text)\n",
                "\n",
                "# Do async prefetching / buffering of the data for best performance on GPU.\n",
                "train_ds = train_ds.cache().prefetch(buffer_size=10)\n",
                "val_ds = val_ds.cache().prefetch(buffer_size=10)\n",
                "test_ds = test_ds.cache().prefetch(buffer_size=10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Modelling"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "(Neptune) Create a new model and model version"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "https://app.neptune.ai/showcase/project-text-classification/m/TXTCLF-KER/v/TXTCLF-KER-7\n",
                        "Remember to stop your model_version once you’ve finished logging your metadata (https://docs.neptune.ai/api/model_version#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
                    ]
                }
            ],
            "source": [
                "from neptune.new.exceptions import NeptuneModelKeyAlreadyExistsError\n",
                "\n",
                "project_key = project[\"sys/id\"].fetch()\n",
                "\n",
                "try:\n",
                "    model = neptune.init_model(name=\"keras\", key=\"KER\")\n",
                "    model.stop()\n",
                "except NeptuneModelKeyAlreadyExistsError:\n",
                "    # If it already exists, we don't have to do anything.\n",
                "    pass\n",
                "\n",
                "model_version = neptune.init_model_version(model=f\"{project_key}-KER\", name=\"keras\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Build a model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_params = {\n",
                "    \"dropout\": 0.5,\n",
                "    \"strides\": 3,\n",
                "    \"activation\": \"relu\",\n",
                "    \"kernel_size\": 7,\n",
                "    \"loss\": \"binary_crossentropy\",\n",
                "    \"optimizer\": \"adam\",\n",
                "    \"metrics\": [\"accuracy\"],\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\siddh\\miniconda3\\envs\\py38\\lib\\site-packages\\neptune\\new\\attributes\\attribute.py:64: NeptuneDeprecationWarning: The object you're logging will be implicitly cast to a string. We'll end support of this behavior in `neptune-client==1.0.0`. To log the object as a string, use `str(object)` instead.\n",
                        "  return self.assign(value, wait)\n"
                    ]
                }
            ],
            "source": [
                "model_version[\"params\"] = model_params"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "keras_model = utils.build_model(model_params, data_params)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Train the model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "(Neptune) Initialize the Neptune callback"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "from neptune.new.integrations.tensorflow_keras import NeptuneCallback\n",
                "\n",
                "neptune_callback = NeptuneCallback(run=run, log_model_diagram=True, log_on_batch=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "training_params = {\n",
                "    \"epochs\": 3,\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/3\n",
                        "625/625 [==============================] - 27s 42ms/step - loss: 0.5130 - accuracy: 0.7061 - val_loss: 0.3016 - val_accuracy: 0.8740\n",
                        "Epoch 2/3\n",
                        "625/625 [==============================] - 27s 43ms/step - loss: 0.2260 - accuracy: 0.9118 - val_loss: 0.3052 - val_accuracy: 0.8836\n",
                        "Epoch 3/3\n",
                        "625/625 [==============================] - 27s 44ms/step - loss: 0.1151 - accuracy: 0.9575 - val_loss: 0.4126 - val_accuracy: 0.8736\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<keras.callbacks.History at 0x1f031afc130>"
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Fit the model using the train and test datasets.\n",
                "keras_model.fit(\n",
                "    train_ds, validation_data=val_ds, epochs=training_params[\"epochs\"], callbacks=neptune_callback\n",
                ")\n",
                "# Training parameters are logged automatically to Neptune"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Evaluate the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "782/782 [==============================] - 10s 13ms/step - loss: 0.4594 - accuracy: 0.8564\n"
                    ]
                }
            ],
            "source": [
                "_, curr_model_acc = keras_model.evaluate(test_ds, callbacks=neptune_callback)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## (Neptune) Associate run with model and vice-versa"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'id': 'TXTCLF-358', 'name': 'Keras text classification', 'url': 'https://app.neptune.ai/showcase/project-text-classification/e/TXTCLF-358'}\n"
                    ]
                }
            ],
            "source": [
                "run_meta = {\n",
                "    \"id\": run[\"sys/id\"].fetch(),\n",
                "    \"name\": run[\"sys/name\"].fetch(),\n",
                "    \"url\": run.get_url(),\n",
                "}\n",
                "\n",
                "print(run_meta)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_version[\"run\"] = run_meta"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'id': 'TXTCLF-KER-7', 'name': 'keras', 'url': 'https://app.neptune.ai/showcase/project-text-classification/m/TXTCLF-KER/v/TXTCLF-KER-7'}\n"
                    ]
                }
            ],
            "source": [
                "model_version_meta = {\n",
                "    \"id\": model_version[\"sys/id\"].fetch(),\n",
                "    \"name\": model_version[\"sys/name\"].fetch(),\n",
                "    \"url\": model_version.get_url(),\n",
                "}\n",
                "\n",
                "print(model_version_meta)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "run[\"training/model/meta\"] = model_version_meta"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## (Neptune) Upload serialized model and model weights to Neptune"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_version[\"serialized_model\"] = keras_model.to_json()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "keras_model.save_weights(\"model_weights.h5\")\n",
                "model_version[\"model_weights\"].upload(\"model_weights.h5\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "(Neptune) Wait for all operations to sync with Neptune servers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_version.sync()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## (Neptune) Promote best model to production"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### (Neptune) Fetch current production model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "https://app.neptune.ai/showcase/project-text-classification/m/TXTCLF-KER\n",
                        "Remember to stop your model once you’ve finished logging your metadata (https://docs.neptune.ai/api/model#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
                        "Shutting down background jobs, please wait a moment...\n",
                        "Done!\n",
                        "All 0 operations synced, thanks for waiting!\n",
                        "Explore the metadata in the Neptune app:\n",
                        "https://app.neptune.ai/showcase/project-text-classification/m/TXTCLF-KER/metadata\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>sys/creation_time</th>\n",
                            "      <th>sys/id</th>\n",
                            "      <th>sys/model_id</th>\n",
                            "      <th>sys/modification_time</th>\n",
                            "      <th>sys/monitoring_time</th>\n",
                            "      <th>sys/name</th>\n",
                            "      <th>sys/owner</th>\n",
                            "      <th>sys/ping_time</th>\n",
                            "      <th>sys/running_time</th>\n",
                            "      <th>sys/size</th>\n",
                            "      <th>...</th>\n",
                            "      <th>params/dropout</th>\n",
                            "      <th>params/kernel_size</th>\n",
                            "      <th>params/loss</th>\n",
                            "      <th>params/metrics</th>\n",
                            "      <th>params/optimizer</th>\n",
                            "      <th>params/strides</th>\n",
                            "      <th>run/id</th>\n",
                            "      <th>run/name</th>\n",
                            "      <th>run/url</th>\n",
                            "      <th>serialized_model</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>2023-01-06 12:18:54.909000+00:00</td>\n",
                            "      <td>TXTCLF-KER-7</td>\n",
                            "      <td>TXTCLF-KER</td>\n",
                            "      <td>2023-01-06 12:20:28.760000+00:00</td>\n",
                            "      <td>89</td>\n",
                            "      <td>keras</td>\n",
                            "      <td>siddhant.sadangi</td>\n",
                            "      <td>2023-01-06 12:20:28.760000+00:00</td>\n",
                            "      <td>93.846</td>\n",
                            "      <td>11255447.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.5</td>\n",
                            "      <td>7</td>\n",
                            "      <td>binary_crossentropy</td>\n",
                            "      <td>['accuracy']</td>\n",
                            "      <td>adam</td>\n",
                            "      <td>3</td>\n",
                            "      <td>TXTCLF-358</td>\n",
                            "      <td>Keras text classification</td>\n",
                            "      <td>https://app.neptune.ai/showcase/project-text-c...</td>\n",
                            "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2023-01-05 18:25:49.330000+00:00</td>\n",
                            "      <td>TXTCLF-KER-6</td>\n",
                            "      <td>TXTCLF-KER</td>\n",
                            "      <td>2023-01-05 18:27:25.769000+00:00</td>\n",
                            "      <td>82</td>\n",
                            "      <td>keras</td>\n",
                            "      <td>siddhant.sadangi</td>\n",
                            "      <td>2023-01-05 18:27:25.769000+00:00</td>\n",
                            "      <td>96.435</td>\n",
                            "      <td>11255451.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.5</td>\n",
                            "      <td>7</td>\n",
                            "      <td>binary_crossentropy</td>\n",
                            "      <td>['accuracy']</td>\n",
                            "      <td>adam</td>\n",
                            "      <td>3</td>\n",
                            "      <td>TXTCLF-356</td>\n",
                            "      <td>Keras text classification</td>\n",
                            "      <td>https://app.neptune.ai/showcase/project-text-c...</td>\n",
                            "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>2023-01-05 18:09:11.474000+00:00</td>\n",
                            "      <td>TXTCLF-KER-5</td>\n",
                            "      <td>TXTCLF-KER</td>\n",
                            "      <td>2023-01-05 18:10:57.264000+00:00</td>\n",
                            "      <td>93</td>\n",
                            "      <td>keras</td>\n",
                            "      <td>siddhant.sadangi</td>\n",
                            "      <td>2023-01-05 18:10:57.264000+00:00</td>\n",
                            "      <td>105.786</td>\n",
                            "      <td>11255451.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.5</td>\n",
                            "      <td>7</td>\n",
                            "      <td>binary_crossentropy</td>\n",
                            "      <td>['accuracy']</td>\n",
                            "      <td>adam</td>\n",
                            "      <td>3</td>\n",
                            "      <td>TXTCLF-354</td>\n",
                            "      <td>Keras text classification</td>\n",
                            "      <td>https://app.neptune.ai/showcase/project-text-c...</td>\n",
                            "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>2023-01-05 18:00:54.375000+00:00</td>\n",
                            "      <td>TXTCLF-KER-4</td>\n",
                            "      <td>TXTCLF-KER</td>\n",
                            "      <td>2023-01-05 18:03:31.043000+00:00</td>\n",
                            "      <td>140</td>\n",
                            "      <td>keras</td>\n",
                            "      <td>siddhant.sadangi</td>\n",
                            "      <td>2023-01-05 18:03:31.043000+00:00</td>\n",
                            "      <td>156.663</td>\n",
                            "      <td>11255731.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.5</td>\n",
                            "      <td>7</td>\n",
                            "      <td>binary_crossentropy</td>\n",
                            "      <td>['accuracy']</td>\n",
                            "      <td>adam</td>\n",
                            "      <td>3</td>\n",
                            "      <td>TXTCLF-352</td>\n",
                            "      <td>Keras text classification</td>\n",
                            "      <td>https://app.neptune.ai/showcase/project-text-c...</td>\n",
                            "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>2023-01-05 17:57:35.457000+00:00</td>\n",
                            "      <td>TXTCLF-KER-3</td>\n",
                            "      <td>TXTCLF-KER</td>\n",
                            "      <td>2023-01-05 18:27:16.564000+00:00</td>\n",
                            "      <td>137</td>\n",
                            "      <td>Untitled</td>\n",
                            "      <td>siddhant.sadangi</td>\n",
                            "      <td>2023-01-05 18:27:16.564000+00:00</td>\n",
                            "      <td>164.422</td>\n",
                            "      <td>11255456.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.5</td>\n",
                            "      <td>7</td>\n",
                            "      <td>binary_crossentropy</td>\n",
                            "      <td>['accuracy']</td>\n",
                            "      <td>adam</td>\n",
                            "      <td>3</td>\n",
                            "      <td>TXTCLF-350</td>\n",
                            "      <td>Keras text classification</td>\n",
                            "      <td>https://app.neptune.ai/showcase/project-text-c...</td>\n",
                            "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>2023-01-05 17:35:27.859000+00:00</td>\n",
                            "      <td>TXTCLF-KER-2</td>\n",
                            "      <td>TXTCLF-KER</td>\n",
                            "      <td>2023-01-05 18:00:09.752000+00:00</td>\n",
                            "      <td>123</td>\n",
                            "      <td>Untitled</td>\n",
                            "      <td>siddhant.sadangi</td>\n",
                            "      <td>2023-01-05 18:16:47.766000+00:00</td>\n",
                            "      <td>2479.781</td>\n",
                            "      <td>11255454.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.5</td>\n",
                            "      <td>7</td>\n",
                            "      <td>binary_crossentropy</td>\n",
                            "      <td>['accuracy']</td>\n",
                            "      <td>adam</td>\n",
                            "      <td>3</td>\n",
                            "      <td>TXTCLF-348</td>\n",
                            "      <td>Keras text classification</td>\n",
                            "      <td>https://app.neptune.ai/showcase/project-text-c...</td>\n",
                            "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>2023-01-05 17:26:18.799000+00:00</td>\n",
                            "      <td>TXTCLF-KER-1</td>\n",
                            "      <td>TXTCLF-KER</td>\n",
                            "      <td>2023-01-05 17:39:34.330000+00:00</td>\n",
                            "      <td>49</td>\n",
                            "      <td>Untitled</td>\n",
                            "      <td>siddhant.sadangi</td>\n",
                            "      <td>2023-01-05 18:16:47.943000+00:00</td>\n",
                            "      <td>2383.721</td>\n",
                            "      <td>4529.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.5</td>\n",
                            "      <td>7</td>\n",
                            "      <td>binary_crossentropy</td>\n",
                            "      <td>['accuracy']</td>\n",
                            "      <td>adam</td>\n",
                            "      <td>3</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>7 rows × 25 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                 sys/creation_time        sys/id sys/model_id  \\\n",
                            "0 2023-01-06 12:18:54.909000+00:00  TXTCLF-KER-7   TXTCLF-KER   \n",
                            "1 2023-01-05 18:25:49.330000+00:00  TXTCLF-KER-6   TXTCLF-KER   \n",
                            "2 2023-01-05 18:09:11.474000+00:00  TXTCLF-KER-5   TXTCLF-KER   \n",
                            "3 2023-01-05 18:00:54.375000+00:00  TXTCLF-KER-4   TXTCLF-KER   \n",
                            "4 2023-01-05 17:57:35.457000+00:00  TXTCLF-KER-3   TXTCLF-KER   \n",
                            "5 2023-01-05 17:35:27.859000+00:00  TXTCLF-KER-2   TXTCLF-KER   \n",
                            "6 2023-01-05 17:26:18.799000+00:00  TXTCLF-KER-1   TXTCLF-KER   \n",
                            "\n",
                            "             sys/modification_time  sys/monitoring_time  sys/name  \\\n",
                            "0 2023-01-06 12:20:28.760000+00:00                   89     keras   \n",
                            "1 2023-01-05 18:27:25.769000+00:00                   82     keras   \n",
                            "2 2023-01-05 18:10:57.264000+00:00                   93     keras   \n",
                            "3 2023-01-05 18:03:31.043000+00:00                  140     keras   \n",
                            "4 2023-01-05 18:27:16.564000+00:00                  137  Untitled   \n",
                            "5 2023-01-05 18:00:09.752000+00:00                  123  Untitled   \n",
                            "6 2023-01-05 17:39:34.330000+00:00                   49  Untitled   \n",
                            "\n",
                            "          sys/owner                    sys/ping_time  sys/running_time  \\\n",
                            "0  siddhant.sadangi 2023-01-06 12:20:28.760000+00:00            93.846   \n",
                            "1  siddhant.sadangi 2023-01-05 18:27:25.769000+00:00            96.435   \n",
                            "2  siddhant.sadangi 2023-01-05 18:10:57.264000+00:00           105.786   \n",
                            "3  siddhant.sadangi 2023-01-05 18:03:31.043000+00:00           156.663   \n",
                            "4  siddhant.sadangi 2023-01-05 18:27:16.564000+00:00           164.422   \n",
                            "5  siddhant.sadangi 2023-01-05 18:16:47.766000+00:00          2479.781   \n",
                            "6  siddhant.sadangi 2023-01-05 18:16:47.943000+00:00          2383.721   \n",
                            "\n",
                            "     sys/size  ... params/dropout params/kernel_size          params/loss  \\\n",
                            "0  11255447.0  ...            0.5                  7  binary_crossentropy   \n",
                            "1  11255451.0  ...            0.5                  7  binary_crossentropy   \n",
                            "2  11255451.0  ...            0.5                  7  binary_crossentropy   \n",
                            "3  11255731.0  ...            0.5                  7  binary_crossentropy   \n",
                            "4  11255456.0  ...            0.5                  7  binary_crossentropy   \n",
                            "5  11255454.0  ...            0.5                  7  binary_crossentropy   \n",
                            "6      4529.0  ...            0.5                  7  binary_crossentropy   \n",
                            "\n",
                            "   params/metrics params/optimizer  params/strides      run/id  \\\n",
                            "0    ['accuracy']             adam               3  TXTCLF-358   \n",
                            "1    ['accuracy']             adam               3  TXTCLF-356   \n",
                            "2    ['accuracy']             adam               3  TXTCLF-354   \n",
                            "3    ['accuracy']             adam               3  TXTCLF-352   \n",
                            "4    ['accuracy']             adam               3  TXTCLF-350   \n",
                            "5    ['accuracy']             adam               3  TXTCLF-348   \n",
                            "6    ['accuracy']             adam               3         NaN   \n",
                            "\n",
                            "                    run/name  \\\n",
                            "0  Keras text classification   \n",
                            "1  Keras text classification   \n",
                            "2  Keras text classification   \n",
                            "3  Keras text classification   \n",
                            "4  Keras text classification   \n",
                            "5  Keras text classification   \n",
                            "6                        NaN   \n",
                            "\n",
                            "                                             run/url  \\\n",
                            "0  https://app.neptune.ai/showcase/project-text-c...   \n",
                            "1  https://app.neptune.ai/showcase/project-text-c...   \n",
                            "2  https://app.neptune.ai/showcase/project-text-c...   \n",
                            "3  https://app.neptune.ai/showcase/project-text-c...   \n",
                            "4  https://app.neptune.ai/showcase/project-text-c...   \n",
                            "5  https://app.neptune.ai/showcase/project-text-c...   \n",
                            "6                                                NaN   \n",
                            "\n",
                            "                                    serialized_model  \n",
                            "0  {\"class_name\": \"Functional\", \"config\": {\"name\"...  \n",
                            "1  {\"class_name\": \"Functional\", \"config\": {\"name\"...  \n",
                            "2  {\"class_name\": \"Functional\", \"config\": {\"name\"...  \n",
                            "3  {\"class_name\": \"Functional\", \"config\": {\"name\"...  \n",
                            "4  {\"class_name\": \"Functional\", \"config\": {\"name\"...  \n",
                            "5  {\"class_name\": \"Functional\", \"config\": {\"name\"...  \n",
                            "6  {\"class_name\": \"Functional\", \"config\": {\"name\"...  \n",
                            "\n",
                            "[7 rows x 25 columns]"
                        ]
                    },
                    "execution_count": 30,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "with neptune.init_model(with_id=f\"{project_key}-KER\") as model:\n",
                "    model_versions_df = model.fetch_model_versions_table().to_pandas()\n",
                "model_versions_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [],
            "source": [
                "production_models = model_versions_df[model_versions_df[\"sys/stage\"] == \"production\"][\"sys/id\"]\n",
                "assert (\n",
                "    len(production_models) == 1\n",
                "), f\"Multiple model versions found in production: {production_models.values}\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Current model in production: TXTCLF-KER-3\n"
                    ]
                }
            ],
            "source": [
                "prod_model_id = production_models.values[0]\n",
                "print(f\"Current model in production: {prod_model_id}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "https://app.neptune.ai/showcase/project-text-classification/m/TXTCLF-KER/v/TXTCLF-KER-3\n",
                        "Remember to stop your model_version once you’ve finished logging your metadata (https://docs.neptune.ai/api/model_version#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
                    ]
                }
            ],
            "source": [
                "npt_prod_model = neptune.init_model_version(with_id=prod_model_id)\n",
                "npt_prod_model_params = npt_prod_model[\"params\"].fetch()\n",
                "prod_model = tf.keras.models.model_from_json(\n",
                "    npt_prod_model[\"serialized_model\"].fetch(), custom_objects=None\n",
                ")\n",
                "\n",
                "npt_prod_model[\"model_weights\"].download()\n",
                "prod_model.load_weights(\"model_weights.h5\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### (Neptune) Evaluate current model on lastest test data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "782/782 [==============================] - 6s 8ms/step - loss: 0.4290 - accuracy: 0.8634\n"
                    ]
                }
            ],
            "source": [
                "# using the model's original loss and optimizer, but the current metric\n",
                "prod_model.compile(\n",
                "    loss=npt_prod_model_params[\"loss\"],\n",
                "    optimizer=npt_prod_model_params[\"optimizer\"],\n",
                "    metrics=model_params[\"metrics\"],\n",
                ")\n",
                "\n",
                "_, prod_model_acc = prod_model.evaluate(test_ds)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### (Neptune) If challenger model outperforms production model, promote it to production"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Production model accuracy: 0.8633599877357483\n",
                        "Challenger model accuracy: 0.8563600182533264\n",
                        "Archiving challenger model\n",
                        "Shutting down background jobs, please wait a moment...\n",
                        "Done!\n",
                        "All 0 operations synced, thanks for waiting!\n",
                        "Explore the metadata in the Neptune app:\n",
                        "https://app.neptune.ai/showcase/project-text-classification/m/TXTCLF-KER/v/TXTCLF-KER-3/metadata\n"
                    ]
                }
            ],
            "source": [
                "print(f\"Production model accuracy: {prod_model_acc}\\nChallenger model accuracy: {curr_model_acc}\")\n",
                "\n",
                "if curr_model_acc > prod_model_acc:\n",
                "    print(\"Promoting challenger to production\")\n",
                "    npt_prod_model.change_stage(\"archived\")\n",
                "    model_version.change_stage(\"production\")\n",
                "else:\n",
                "    print(\"Archiving challenger model\")\n",
                "    model_version.change_stage(\"archived\")\n",
                "\n",
                "npt_prod_model.stop()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## (Neptune) Stop tracking"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Shutting down background jobs, please wait a moment...\n",
                        "Done!\n",
                        "All 0 operations synced, thanks for waiting!\n",
                        "Explore the metadata in the Neptune app:\n",
                        "https://app.neptune.ai/showcase/project-text-classification/m/TXTCLF-KER/v/TXTCLF-KER-7/metadata\n",
                        "Shutting down background jobs, please wait a moment...\n",
                        "Done!\n",
                        "Waiting for the remaining 6 operations to synchronize with Neptune. Do not kill this process.\n",
                        "All 6 operations synced, thanks for waiting!\n",
                        "Explore the metadata in the Neptune app:\n",
                        "https://app.neptune.ai/showcase/project-text-classification/e/TXTCLF-358\n",
                        "Shutting down background jobs, please wait a moment...\n",
                        "Done!\n",
                        "All 0 operations synced, thanks for waiting!\n",
                        "Explore the metadata in the Neptune app:\n",
                        "https://app.neptune.ai/showcase/project-text-classification/metadata\n"
                    ]
                }
            ],
            "source": [
                "model_version.stop()\n",
                "run.stop()\n",
                "project.stop()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:42:03) [MSC v.1929 64 bit (AMD64)]"
        },
        "neptune": {
            "notebookId": "9828a187-2d06-4d81-847c-61066b3f0790",
            "projectVersion": 2
        },
        "vscode": {
            "interpreter": {
                "hash": "a9715cf0b0024f6e1c62cb31a4f1f43970eb41991212681878768b4bfe53050a"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
